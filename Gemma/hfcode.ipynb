{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a594ce463ea4d6796aec68afe377280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc85ef0383d46ecb264c58eb95df868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "def generate_chat_response(system_prompt, user_prompt, max_length=128, max_tokens=None):\n",
    "    \"\"\"\n",
    "    Function to generate a chat response given a system and user prompt.\n",
    "\n",
    "    Args:\n",
    "        system_prompt (str): The system prompt that sets the behavior of the model.\n",
    "        user_prompt (str): The user's input to the model.\n",
    "        max_length (int, optional): The maximum total length of the response including the input.\n",
    "        max_tokens (int, optional): The maximum number of tokens for the newly generated response.\n",
    "\n",
    "    Returns:\n",
    "        str: The model's response.\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine system and user prompts into a single input\n",
    "    combined_prompt = f\"System: {system_prompt}\\nUser: {user_prompt}\\nAssistant:\"\n",
    "\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(combined_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Set generation parameters\n",
    "    generation_kwargs = {\n",
    "        \"max_length\": max_length,\n",
    "        \"pad_token_id\": tokenizer.eos_token_id\n",
    "    }\n",
    "    if max_tokens:\n",
    "        generation_kwargs[\"max_new_tokens\"] = max_tokens\n",
    "\n",
    "    # Generate the response\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        **generation_kwargs\n",
    "    )\n",
    "\n",
    "    # Decode and return the response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract only the assistant's response\n",
    "    assistant_response = response.split(\"Assistant:\")[-1].strip()\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=1000) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Of course! Here's a breakdown of photosynthesis:\n",
       "\n",
       "**What is Photosynthesis?**\n",
       "\n",
       "Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with chemical energy.  \n",
       "\n",
       "**The Basics:**\n",
       "\n",
       "* **Sunlight:** Plants absorb light energy from the sun.\n",
       "* **Carbon Dioxide:** Plants take in carbon dioxide from the air through tiny openings on their leaves called stomata.\n",
       "* **Water:** Plants absorb water from the soil through their roots.\n",
       "* **Chlorophyll:** The green pigment in plants called chlorophyll captures light energy.\n",
       "\n",
       "**The Process:**\n",
       "\n",
       "1. **Light-dependent reactions:**\n",
       "   * Chlorophyll absorbs light energy.\n",
       "   * This energy is used to split water molecules into hydrogen and oxygen.\n",
       "   * The oxygen is released into the atmosphere.\n",
       "   * The hydrogen is used to create energy carriers (ATP and NADPH).\n",
       "\n",
       "2. **Light-independent reactions (Calvin Cycle):**\n",
       "   * Carbon dioxide is captured from the air.\n",
       "   * Using the energy from ATP and NADPH created in the light-dependent reactions, carbon dioxide is converted into glucose (a sugar).\n",
       "   * Glucose is the plant's food source.\n",
       "\n",
       "**The Equation:**\n",
       "\n",
       "The overall equation for photosynthesis is:\n",
       "\n",
       "**6CO₂ + 6H₂O + Light Energy → C₆H₁₂O₆ + 6O₂**\n",
       "\n",
       "**Where:**\n",
       "\n",
       "* **CO₂:** Carbon dioxide\n",
       "* **H₂O:** Water\n",
       "* **C₆H₁₂O₆:** Glucose (sugar)\n",
       "* **O₂:** Oxygen\n",
       "\n",
       "**Why is Photosynthesis Important?**\n",
       "\n",
       "* **Food Source:** Photosynthesis is the primary source of energy for almost all life on Earth.\n",
       "* **Oxygen Production:** It releases oxygen into the atmosphere, which is essential for the survival of most organisms.\n",
       "* **Carbon Sink:** Plants absorb carbon dioxide from the atmosphere, helping to regulate the Earth's climate.\n",
       "\n",
       "\n",
       "Let me know if you have any other questions!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Can you explain how photosynthesis works?\"\n",
    "response = generate_chat_response(system_prompt, user_prompt, max_length=200, max_tokens=1000)\n",
    "display_markdown(response, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=1000) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "CASE is a platform that supports the bank's data science, analytics, and MLOps teams. It provides features like a chatbot called CASEY, a non-AI chatbot built on MS Copilot Studio, a collective intelligence framework, a conditional ticketing system, and a search engine powered by MS Graph. This platform helps product and support teams to efficiently address customer needs, manage product knowledge documentation, and handle product inquiries.\n",
       "\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "The paraphrased text maintains the original meaning of the text while using different words and sentence structures. \n",
       "\n",
       "Here's a breakdown of the changes:\n",
       "\n",
       "* **Replaced \"Central Analytics Support & Enablement (CASE)\" with \"CASE is a platform that supports the bank's data science, analytics, and MLOps teams.\"** This rephrases the initial statement for clarity and conciseness.\n",
       "* **Replaced \"CASE includes multiple features such as...\" with \"CASE provides features like...\"** This rephrases the sentence for a more direct and active voice.\n",
       "* **Replaced \"CASEY chatbot, an intent-driven (i.e. non-Gen AI/non-LLM) chatbot microservice built on MS Copilot Studio\" with \"a non-AI chatbot called CASEY, built on MS Copilot Studio.\"** This rephrases the sentence for clarity and conciseness.\n",
       "* **Replaced \"Additionally, CASE includes the Collective Intelligence (CI) framework, conditional ticketing system, and MS Graph-enabled search\" with \"This platform also includes a collective intelligence framework, a conditional ticketing system, and a search engine powered by MS Graph.\"** This rephrases the sentence for clarity and conciseness.\n",
       "* **Replaced \"All of this enables product and support teams to efficiently address customer needs, manage their product knowledge documentation, and handle product inquiries within a unified platform\" with \"This platform helps product and support teams to efficiently address customer needs, manage product knowledge documentation, and handle product inquiries.\"** This rephrases the sentence for clarity and conciseness.\n",
       "\n",
       "\n",
       "Overall, the paraphrased text is more concise and easier to understand."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Basic Paraphasing\n",
    "# Example system and user prompts\n",
    "system_prompt = \"\"\"\n",
    "You are a basic paraphrasing tool that paraphrases all text given.\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "\n",
    "Paraphrase the following text:\n",
    "\n",
    "Central Analytics Support & Enablement (CASE) is our enterprise support platform for the ~20k+ data scientists, data analysts, MLOps engineers, BI developers, etc. at the bank.\n",
    "CASE includes multiple features such as \"CASEY\" chatbot, an intent-driven (i.e. non-Gen AI/non-LLM) chatbot microservice built on MS Copilot Studio.\n",
    "Additionally, CASE includes the Collective Intelligence (CI) framework, conditional ticketing system, and MS Graph-enabled search.\n",
    "All of this enables product and support teams to efficiently address customer needs, manage their product knowledge documentation, and handle product inquiries within a unified platform.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generate and print the response\n",
    "response = generate_chat_response(system_prompt, user_prompt, max_length=200, max_tokens=1000)\n",
    "display_markdown(response, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=1000) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "CASE is a comprehensive platform that supports data science and analytics professionals at the bank. It provides a range of features, including a chatbot, a ticketing system, and a search engine. CASE enables product and support teams to efficiently address customer needs, manage product knowledge, and handle inquiries. \n",
       "\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "The original text is quite verbose and uses a lot of jargon. The paraphrased text is more concise and uses simpler language. \n",
       "\n",
       "**Here are some specific changes made:**\n",
       "\n",
       "* **Replaced \"Central Analytics Support & Enablement (CASE)\" with \"CASE is a comprehensive platform\"** - This is a more direct and concise way to introduce the platform.\n",
       "* **Replaced \"multiple features such as...\" with \"It provides a range of features, including...\"** - This removes the need for a list and makes the text more concise.\n",
       "* **Replaced \"CASEY chatbot, an intent-driven (i.e. non-Gen AI/non-LLM) chatbot microservice built on MS Copilot Studio\" with \"a chatbot, a ticketing system, and a search engine\"** - This simplifies the description of the chatbot and focuses on the key features.\n",
       "* **Replaced \"All of this enables product and support teams to efficiently address customer needs, manage their product knowledge documentation, and handle product inquiries within a unified platform\" with \"CASE enables product and support teams to efficiently address customer needs, manage product knowledge, and handle inquiries.\"** - This removes unnecessary words and makes the sentence more direct.\n",
       "\n",
       "\n",
       "Overall, the paraphrased text is more concise and direct, making it easier for the Model Risk Management team to understand the information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Refined Paraphasing\n",
    "# Example system and user prompts\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "Your task is to be a precise paraphrasing tool for the Model Risk Management team.\n",
    "Reword this text to make it more concise and direct, eliminating any chance for ambiguity\"\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "\n",
    "Paraphrase the following text:\n",
    "\n",
    "Central Analytics Support & Enablement (CASE) is our enterprise support platform for the ~20k+ data scientists, data analysts, MLOps engineers, BI developers, etc. at the bank.\n",
    "CASE includes multiple features such as \"CASEY\" chatbot, an intent-driven (i.e. non-Gen AI/non-LLM) chatbot microservice built on MS Copilot Studio.\n",
    "Additionally, CASE includes the Collective Intelligence (CI) framework, conditional ticketing system, and MS Graph-enabled search.\n",
    "All of this enables product and support teams to efficiently address customer needs, manage their product knowledge documentation, and handle product inquiries within a unified platform.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generate and print the response\n",
    "response = generate_chat_response(system_prompt, user_prompt, max_length=200, max_tokens=1000)\n",
    "display_markdown(response, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=1000) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This text describes Central Analytics Support & Enablement (CASE), an enterprise support platform for a large bank. \n",
       "\n",
       "CASE provides a range of features, including:\n",
       "\n",
       "* **CASEY:** An intent-driven chatbot built on MS Copilot Studio.\n",
       "* **Collective Intelligence (CI) framework:** A system for managing product knowledge and customer inquiries.\n",
       "* **Conditional ticketing system:** A system for managing support requests.\n",
       "* **MS Graph-enabled search:** A system for searching product knowledge and support documentation.\n",
       "\n",
       "These features enable product and support teams to efficiently address customer needs, manage product knowledge documentation, and handle product inquiries within a unified platform. \n",
       "\n",
       "\n",
       "**Key takeaways:**\n",
       "\n",
       "* CASE is a comprehensive platform for data science and analytics professionals at the bank.\n",
       "* CASE offers a range of features to support product and support teams.\n",
       "* CASE helps to improve efficiency and effectiveness in addressing customer needs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Basic Summarization\n",
    "# Example system and user prompts\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "You are a basic summarization tool that summarizes all text given.\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "\n",
    "Summarize the following text:\n",
    "\n",
    "Central Analytics Support & Enablement (CASE) is our enterprise support platform for the ~20k+ data scientists, data analysts, MLOps engineers, BI developers, etc. at the bank.\n",
    "CASE includes multiple features such as \"CASEY\" chatbot, an intent-driven (i.e. non-Gen AI/non-LLM) chatbot microservice built on MS Copilot Studio.\n",
    "Additionally, CASE includes the Collective Intelligence (CI) framework, conditional ticketing system, and MS Graph-enabled search.\n",
    "All of this enables product and support teams to efficiently address customer needs, manage their product knowledge documentation, and handle product inquiries within a unified platform.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generate and print the response\n",
    "response = generate_chat_response(system_prompt, user_prompt, max_length=200, max_tokens=1000)\n",
    "display_markdown(response, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=1000) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here's a summary of the text, focusing on strategic recommendations and potential challenges:\n",
       "\n",
       "**Summary:**\n",
       "\n",
       "CASE is a comprehensive platform designed to support data science and analytics professionals at the bank. It offers a range of features, including a chatbot, a ticketing system, and a search engine, all integrated into a single platform.\n",
       "\n",
       "**Strategic Recommendations:**\n",
       "\n",
       "* **Expand CASE's AI capabilities:**  While CASE currently utilizes a non-Gen AI/non-LLM chatbot, exploring the integration of AI-powered features could significantly enhance its capabilities. This could include incorporating natural language processing (NLP) for more sophisticated interactions, sentiment analysis for understanding customer emotions, and predictive analytics for proactive support.\n",
       "* **Enhance the Collective Intelligence (CI) framework:**  The CI framework is a valuable tool for knowledge management. However, its effectiveness depends on user adoption and participation.  Encouraging active participation and providing clear guidelines for contributing to the CI framework could improve its impact.\n",
       "* **Integrate CASE with other systems:**  Integrating CASE with other systems, such as data warehouses, data lakes, and machine learning platforms, could provide a more holistic view of data and analytics activities. This could facilitate better collaboration and knowledge sharing across the organization.\n",
       "\n",
       "**Potential Challenges:**\n",
       "\n",
       "* **Resistance to change:**  Introducing a new platform like CASE could face resistance from users accustomed to existing workflows.  Effective communication and training are crucial to ensure smooth adoption.\n",
       "* **Data security and privacy:**  As CASE handles sensitive data, ensuring robust security measures and compliance with data privacy regulations is paramount.\n",
       "* **Integration complexity:**  Integrating CASE with existing systems can be complex and time-consuming.  Careful planning and execution are essential to avoid delays and disruptions.\n",
       "* **Cost and scalability:**  Implementing and maintaining CASE may require significant financial resources.  The platform's scalability needs to be considered to accommodate future growth.\n",
       "\n",
       "\n",
       "**Overall:**\n",
       "\n",
       "CASE is a valuable asset for the bank's data science and analytics teams. By focusing on strategic recommendations and addressing potential challenges, the bank can maximize the platform's potential and drive greater efficiency and innovation in its data-driven operations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Refined Summarization\n",
    "# Example system and user prompts\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "Your task is to be a precise summarization tool for the Model Risk Management team.\n",
    "Provide a summary of this passage with a emphasis on strategic recommendations, and any key challenges that could occur.\"\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "\n",
    "Summarize the following text:\n",
    "\n",
    "Central Analytics Support & Enablement (CASE) is our enterprise support platform for the ~20k+ data scientists, data analysts, MLOps engineers, BI developers, etc. at the bank.\n",
    "CASE includes multiple features such as \"CASEY\" chatbot, an intent-driven (i.e. non-Gen AI/non-LLM) chatbot microservice built on MS Copilot Studio.\n",
    "Additionally, CASE includes the Collective Intelligence (CI) framework, conditional ticketing system, and MS Graph-enabled search.\n",
    "All of this enables product and support teams to efficiently address customer needs, manage their product knowledge documentation, and handle product inquiries within a unified platform.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generate and print the response\n",
    "response = generate_chat_response(system_prompt, user_prompt, max_length=200, max_tokens=1000)\n",
    "display_markdown(response, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=1000) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The text is grammatically correct, but it could be improved in terms of clarity and conciseness. Here are some suggestions:\n",
       "\n",
       "* **Replace \"Central Analytics Support & Enablement (CASE)\" with \"CASE\" for brevity.**\n",
       "* **Combine the sentences about CASE features into one sentence for better flow.**\n",
       "* **Use more specific language when describing the benefits of CASE.**\n",
       "\n",
       "Here's a revised version of the text:\n",
       "\n",
       "CASE, our enterprise support platform for the ~20k+ data scientists, data analysts, MLOps engineers, BI developers, etc., at the bank, includes multiple features such as the CASEY chatbot, an intent-driven chatbot microservice built on MS Copilot Studio. CASE also includes the Collective Intelligence (CI) framework, a conditional ticketing system, and MS Graph-enabled search. This unified platform enables product and support teams to efficiently address customer needs, manage product knowledge documentation, and handle product inquiries.\n",
       "\n",
       "\n",
       "**Explanation of Changes:**\n",
       "\n",
       "* **CASE:** Replacing the full name with \"CASE\" for brevity and clarity.\n",
       "* **Combined Sentences:** Combining the sentences about CASE features into one for better flow and readability.\n",
       "* **Specific Language:** Replacing vague terms like \"efficiently address customer needs\" with more specific language like \"efficiently address customer needs, manage product knowledge documentation, and handle product inquiries.\"\n",
       "\n",
       "\n",
       "**Additional Suggestions:**\n",
       "\n",
       "* **Consider adding a sentence about the impact of CASE on the bank's overall operations.**\n",
       "* **Use active voice whenever possible for a more direct and engaging tone.**\n",
       "* **Proofread for any remaining typos or grammatical errors.**\n",
       "\n",
       "\n",
       "Let me know if you have any other text you'd like me to check!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Basic Grammar Checking\n",
    "# Example system and user prompts\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "You are a basic Grammar Checking tool that checks all text given.\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "\n",
    "Grammar Check the following text:\n",
    "\n",
    "Central Analytics Support & Enablement (CASE) is our enterprise support platform for the ~20k+ data scientists, data analysts, MLOps engineers, BI developers, etc. at the bank.\n",
    "CASE includes multiple features such as \"CASEY\" chatbot, an intent-driven (i.e. non-Gen AI/non-LLM) chatbot microservice built on MS Copilot Studio.\n",
    "Additionally, CASE includes the Collective Intelligence (CI) framework, conditional ticketing system, and MS Graph-enabled search.\n",
    "All of this enables product and support teams to efficiently address customer needs, manage their product knowledge documentation, and handle product inquiries within a unified platform.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generate and print the response\n",
    "response = generate_chat_response(system_prompt, user_prompt, max_length=200, max_tokens=1000)\n",
    "display_markdown(response, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=1000) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The text is grammatically correct, but it could be improved for clarity and style. Here's a revised version:\n",
       "\n",
       "**Central Analytics Support & Enablement (CASE) is the enterprise support platform for the ~20,000 data scientists, data analysts, MLOps engineers, BI developers, and other data professionals at the bank. \n",
       "\n",
       "CASE offers a range of features, including the \"CASEY\" chatbot, an intent-driven chatbot microservice built on Microsoft Copilot Studio. \n",
       "\n",
       "Additionally, CASE includes the Collective Intelligence (CI) framework, a conditional ticketing system, and MS Graph-enabled search. \n",
       "\n",
       "These features enable product and support teams to efficiently address customer needs, manage product knowledge documentation, and handle product inquiries within a unified platform. **\n",
       "\n",
       "**Changes:**\n",
       "\n",
       "* **Clarity:**  The original text was a bit clunky. The revised version uses more concise language and clarifies the target audience.\n",
       "* **Style:** The revised version uses active voice and avoids unnecessary repetition.\n",
       "* **Formal Tone:** The revised version maintains a formal and professional tone.\n",
       "\n",
       "\n",
       "**Additional Suggestions:**\n",
       "\n",
       "* **Consistency:**  Ensure consistency in capitalization and formatting throughout the document.\n",
       "* **Conciseness:**  Avoid unnecessary words or phrases.\n",
       "* **Audience:**  Consider the specific audience for this text and tailor the language accordingly. \n",
       "\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "The original text was grammatically correct, but it lacked clarity and conciseness. The revised version improves these aspects by using more concise language and clarifying the target audience. The changes also ensure a formal and professional tone. \n",
       "\n",
       "\n",
       "**Note:** \n",
       "The original text was a bit informal and could be improved for a more formal professional setting."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Refined Grammar Checking\n",
    "# Example system and user prompts\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "Your task is to be a precise Grammar Checking tool for the Model Risk Management team.\n",
    "Assess the provided text for grammatical accuracy and suitabillity for a formal professional setting.\n",
    "Provide an enhnaced version with corrections and improved stylistic flow.\"\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "\n",
    "Grammar Check the following text:\n",
    "\n",
    "Central Analytics Support & Enablement (CASE) is our enterprise support platform for the ~20k+ data scientists, data analysts, MLOps engineers, BI developers, etc. at the bank.\n",
    "CASE includes multiple features such as \"CASEY\" chatbot, an intent-driven (i.e. non-Gen AI/non-LLM) chatbot microservice built on MS Copilot Studio.\n",
    "Additionally, CASE includes the Collective Intelligence (CI) framework, conditional ticketing system, and MS Graph-enabled search.\n",
    "All of this enables product and support teams to efficiently address customer needs, manage their product knowledge documentation, and handle product inquiries within a unified platform.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generate and print the response\n",
    "response = generate_chat_response(system_prompt, user_prompt, max_length=200, max_tokens=1000)\n",
    "display_markdown(response, raw=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
