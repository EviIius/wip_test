{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# DOCUMENT GENERATION WITH GUIDELINES\n",
    "# ------------------------------------------------------------------------------\n",
    "def generate_document_with_guidelines(\n",
    "    user_query: str,\n",
    "    guidelines: List[str],\n",
    "    vector_store: VectorStore,\n",
    "    k: int = 3,\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 0.7\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Searches the VectorStore for relevant doc chunks based on user_query,\n",
    "    then iterates over each guideline to produce a separate snippet.\n",
    "    Returns one combined \"document\" with all guideline-based responses.\n",
    "    \"\"\"\n",
    "    # 1) Retrieve top-k relevant documents\n",
    "    search_results = vector_store.search(user_query, k=k)\n",
    "\n",
    "    # 2) Build a single combined context from the top docs\n",
    "    combined_context_parts = []\n",
    "    for doc, sim_score in search_results:\n",
    "        meta_str = \"\"\n",
    "        if doc.metadata:\n",
    "            meta_parts = [f\"{key}: {val}\" for key, val in doc.metadata.items()]\n",
    "            meta_str = \"\\n\".join(meta_parts)\n",
    "\n",
    "        context_str = (\n",
    "            f\"---\\nContent:\\n{doc.content}\\n\"\n",
    "            f\"Metadata:\\n{meta_str}\\n\"\n",
    "            f\"Similarity Score: {sim_score:.4f}\\n---\"\n",
    "        )\n",
    "        combined_context_parts.append(context_str)\n",
    "    combined_context = \"\\n\\n\".join(combined_context_parts)\n",
    "\n",
    "    # 3) Loop over each guideline, generate a snippet\n",
    "    final_snippets = []\n",
    "    for idx, guideline in enumerate(guidelines, start=1):\n",
    "        prompt = f\"\"\"\n",
    "You have the following user query:\n",
    "{user_query}\n",
    "\n",
    "Context from relevant documents (with metadata):\n",
    "{combined_context}\n",
    "\n",
    "Guideline #{idx}: {guideline}\n",
    "\n",
    "Based on the user query and the above context, create a concise \n",
    "section of a final document that follows this guideline. \n",
    "Use only the provided context if needed.\n",
    "\"\"\"\n",
    "        snippet = get_completion(\n",
    "            prompt,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        formatted_snippet = f\"### GUIDELINE #{idx}: {guideline}\\n{snippet.strip()}\\n\"\n",
    "        final_snippets.append(formatted_snippet)\n",
    "\n",
    "    # 4) Combine all guideline-based snippets\n",
    "    final_document = \"\\n\\n\".join(final_snippets)\n",
    "    return final_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# EXAMPLE USAGE (Comment out if you only want library code)\n",
    "# ------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Suppose we load & chunk a sample file (PDF, TXT, or CSV)\n",
    "    file_path = \"sample.txt\"  # adjust to your actual file\n",
    "    doc_chunks = DocumentProcessor.load_and_chunk_file(file_path)\n",
    "\n",
    "    # 2) Create a vector store and index the doc chunks\n",
    "    vs = VectorStore(persist_directory=\"rag_index\")\n",
    "    vs.create_index(doc_chunks, force_recreate=True)\n",
    "\n",
    "    # 3) Some example guidelines\n",
    "    my_guidelines = [\n",
    "        \"Provide a step-by-step approach.\",\n",
    "        \"Use plain language for a broad audience.\"\n",
    "    ]\n",
    "\n",
    "    # 4) Generate a combined doc addressing each guideline\n",
    "    user_query = \"How can I plan my personal finances effectively?\"\n",
    "    final_doc = generate_document_with_guidelines(\n",
    "        user_query=user_query,\n",
    "        guidelines=my_guidelines,\n",
    "        vector_store=vs,\n",
    "        k=3,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    print(\"\\n===== FINAL DOCUMENT =====\\n\")\n",
    "    print(final_doc)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
