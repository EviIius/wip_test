{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load a file (PDF, TXT, or CSV), clean the text, and chunk it into Document objects.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        text = DocumentProcessor.load_pdf(file_path)\n",
    "    elif ext == \".txt\":\n",
    "        text = DocumentProcessor.load_txt(file_path)\n",
    "    elif ext == \".csv\":\n",
    "        text = DocumentProcessor.load_csv(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "\n",
    "    # Chunk the text\n",
    "    documents = DocumentProcessor.chunk_text(text)\n",
    "    return documents\n",
    "\n",
    "\n",
    "def load_documents(file_path):\n",
    "    \"\"\"\n",
    "    Load a file (PDF, TXT, or CSV) into Documents, then create a new VectorStore index.\n",
    "    \"\"\"\n",
    "    # Load and chunk document\n",
    "    documents = load_file(file_path)\n",
    "\n",
    "    # Create and return vector store\n",
    "    vector_store = VectorStore()  # or HybridSearcher() if you want both vector + keyword\n",
    "    vector_store.create_index(documents, force_recreate=True)\n",
    "    print(f\"Processed {len(documents)} chunks from file: {file_path}\")\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "vector_store = load_documents(\"/commons/corpra_share/k152356/ReAct_Testing/metatext.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# DOCUMENT GENERATION WITH GUIDELINES\n",
    "# ------------------------------------------------------------------------------\n",
    "def generate_document_with_guidelines(\n",
    "    user_query: str,\n",
    "    guidelines: List[str],\n",
    "    vector_store: VectorStore,\n",
    "    k: int = 3,\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 0.7\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Searches the VectorStore for relevant doc chunks based on user_query,\n",
    "    then iterates over each guideline to produce a separate snippet.\n",
    "    Returns one combined \"document\" with all guideline-based responses.\n",
    "    \"\"\"\n",
    "    # 1) Retrieve top-k relevant documents\n",
    "    search_results = vector_store.search(user_query, k=k)\n",
    "\n",
    "    # 2) Build a single combined context from the top docs\n",
    "    combined_context_parts = []\n",
    "    for doc, sim_score in search_results:\n",
    "        meta_str = \"\"\n",
    "        if doc.metadata:\n",
    "            meta_parts = [f\"{key}: {val}\" for key, val in doc.metadata.items()]\n",
    "            meta_str = \"\\n\".join(meta_parts)\n",
    "\n",
    "        context_str = (\n",
    "            f\"---\\nContent:\\n{doc.content}\\n\"\n",
    "            f\"Metadata:\\n{meta_str}\\n\"\n",
    "            f\"Similarity Score: {sim_score:.4f}\\n---\"\n",
    "        )\n",
    "        combined_context_parts.append(context_str)\n",
    "    combined_context = \"\\n\\n\".join(combined_context_parts)\n",
    "\n",
    "    # 3) Loop over each guideline, generate a snippet\n",
    "    final_snippets = []\n",
    "    for idx, guideline in enumerate(guidelines, start=1):\n",
    "        prompt = f\"\"\"\n",
    "You have the following user query:\n",
    "{user_query}\n",
    "\n",
    "Context from relevant documents (with metadata):\n",
    "{combined_context}\n",
    "\n",
    "Guideline #{idx}: {guideline}\n",
    "\n",
    "Based on the user query and the above context, create a concise \n",
    "section of a final document that follows this guideline. \n",
    "Use only the provided context if needed.\n",
    "\"\"\"\n",
    "        snippet = get_completion(\n",
    "            prompt,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        formatted_snippet = f\"### GUIDELINE #{idx}: {guideline}\\n{snippet.strip()}\\n\"\n",
    "        final_snippets.append(formatted_snippet)\n",
    "\n",
    "    # 4) Combine all guideline-based snippets\n",
    "    final_document = \"\\n\\n\".join(final_snippets)\n",
    "    return final_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_document_with_guidelines(\n",
    "    user_query: str,\n",
    "    guidelines: list,\n",
    "    vector_store: VectorStore,\n",
    "    k: int = 3,\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 0.7\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Searches the VectorStore for relevant document chunks based on user_query,\n",
    "    then iterates over each guideline to produce a separate snippet.\n",
    "    Returns one combined \"document\" with all guideline-based responses.\n",
    "    \n",
    "    Parameters:\n",
    "      user_query (str): The model validation question.\n",
    "      guidelines (list): A list of guideline strings that define sections of the final document.\n",
    "      vector_store (VectorStore): An instance of the VectorStore used for retrieving context.\n",
    "      k (int): The number of top documents to retrieve from the vector store.\n",
    "      max_new_tokens (int): Maximum tokens for each generated snippet.\n",
    "      temperature (float): Sampling temperature for generation.\n",
    "    \n",
    "    Returns:\n",
    "      str: The final combined document based on the generated guideline sections.\n",
    "    \"\"\"\n",
    "    # 1) Retrieve top-k relevant documents\n",
    "    search_results = vector_store.search(user_query, k=k)\n",
    "\n",
    "    # 2) Build a combined context from the top documents\n",
    "    combined_context_parts = []\n",
    "    for doc, sim_score in search_results:\n",
    "        meta_str = \"\"\n",
    "        if doc.metadata:\n",
    "            meta_parts = [f\"{key}: {val}\" for key, val in doc.metadata.items()]\n",
    "            meta_str = \"\\n\".join(meta_parts)\n",
    "        context_str = (\n",
    "            f\"---\\nContent:\\n{doc.content}\\n\"\n",
    "            f\"Metadata:\\n{meta_str}\\n\"\n",
    "            f\"Similarity Score: {sim_score:.4f}\\n---\"\n",
    "        )\n",
    "        combined_context_parts.append(context_str)\n",
    "    combined_context = \"\\n\\n\".join(combined_context_parts)\n",
    "\n",
    "    # 3) Iterate over each guideline and generate the associated snippet\n",
    "    final_snippets = []\n",
    "    for idx, guideline in enumerate(guidelines, start=1):\n",
    "        prompt = f\"\"\"\n",
    "Using this RAG function, I want you to implement a hardcoded version of the ReAct framework to do the following:\n",
    "Your task is to assist a Quantitative Model Validator working in the Model Risk Management team of a bank, to find answers to policy questions about Model Development Document (MDD) based on the provided context.\n",
    "Contents of the subsection(s) of MDD is used as the only input context to answer the Model Validation policy questions. You are a highly accurate assistant who strictly answers only based on the information in the provided context.\n",
    "\n",
    "Strictly follow these Generation Instructions:\n",
    "- Your response should be accurate, coherent, detailed, and descriptive by including all the important statistics, tables, terminologies, and definitions.\n",
    "- Your response should be relevant to the question being asked.\n",
    "- Your response should be honest, focused, and grounded in the provided context.\n",
    "- Do not change or assume any definition, terminology, statistical data, numerical information, or table information.\n",
    "- Always respond with \"Not found\" when you cannot find relevant information in the context.\n",
    "- Always respond with \"Not found\" if any information asked is not explicitly mentioned.\n",
    "- Use the important keywords and phrases from the context to frame your response.\n",
    "- Use bullet points only when required.\n",
    "- Only use the information provided under the specific product, business segment or aspect when answering questions. If the context includes details about multiple products, ensure your response is limited to the product specified in the query. Do not include information from other products, businesses, or other aspects.\n",
    "\n",
    "You have the following user query:\n",
    "{user_query}\n",
    "\n",
    "Context from relevant documents (with metadata):\n",
    "{combined_context}\n",
    "\n",
    "Guideline #{idx}: {guideline}\n",
    "\n",
    "Based on the user query and the above context, create a concise section of a final document that follows this guideline.\n",
    "Focus on using the available context effectively.\n",
    "\"\"\"\n",
    "        # Generate snippet using the LLaMA model's get_completion function\n",
    "        snippet = get_completion(prompt, max_new_tokens=max_new_tokens, temperature=temperature)\n",
    "        formatted_snippet = f\"### GUIDELINE #{idx}: {guideline}\\n{snippet.strip()}\\n\"\n",
    "        final_snippets.append(formatted_snippet)\n",
    "\n",
    "    # 4) Combine all guideline-based snippets into one document\n",
    "    final_document = \"\\n\\n\".join(final_snippets)\n",
    "    return final_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Define a sample user query and a list of guidelines for generating the document sections.\n",
    "    user_query = \"Describe the growth of the portfolio over the past 5, 10 years.\"\n",
    "    guidelines = [\n",
    "        \"Briefly describe the business portfolio to which the model applies\",\n",
    "        \"Include the products and business segments offered by the business line\",\n",
    "        \"Describe the products of the LOB and portfolio to which this model applies.\",\n",
    "        \"Describe any current or planned changes in the products, channels, policies, programs, organization, or marketing practices that may impact the model under consideration.\",\n",
    "        \"Assess how close the current customer base to the target customer profile is.\",\n",
    "        \"Consider whether the customer base is likely to shift over the lifetime of the model.\",\n",
    "        \"Specify the current and possible future market conditions and the impact they may have on the portfolio and the model.\",\n",
    "        \"Describe the growth of the portfolio over the past 5, 10, X years, both in size and in significance to the balance sheet.\",\n",
    "        \"If this is a revalidation or the model replaces an existing model, highlight the key relevant changes on the business between the previous model developments and model validations, and this validation.\",\n",
    "        \"Include all the changes related to modeling, such as model framework and theory, variables, data sources, and programs; business changes, such as policy or strategy; environmental changes, such as competitor actions, economic changes, and political or regulatory changes; and any other changes that impact the model, its implementation, evaluation, and usage.\",\n",
    "        \"Include a table or summary of the portfolio, product, or business metrics of the business in the most recent and past periods. These can include metrics such as balances, losses, recoveries, number of accounts, average account size, credit limits, etc.\"\n",
    "    ]\n",
    "\n",
    "    # Generate the final document by integrating the context with guideline responses.\n",
    "    final_document = generate_document_with_guidelines(\n",
    "        user_query=user_query,\n",
    "        guidelines=guidelines,\n",
    "        vector_store=vector_store,  # Assuming vector_store is defined and initialized\n",
    "        k=3,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    print(\"Final Document:\")\n",
    "    print(final_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_validation_policy_questions_fixed(guidelines, vector_store, max_context_tokens=900):\n",
    "    \"\"\"\n",
    "    For each policy guideline, this function retrieves relevant context using the provided vector_store,\n",
    "    truncates the context if it is too long, and then uses a system prompt (with strict instructions)\n",
    "    to generate an answer based only on that context.\n",
    "\n",
    "    If no relevant context is retrieved, it responds with \"Not found\".\n",
    "    \n",
    "    Args:\n",
    "        guidelines (list): A list of policy guideline questions.\n",
    "        vector_store: An initialized vector store with a search(query, k) method.\n",
    "        max_context_tokens (int): Maximum number of tokens to include for context.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A mapping from each guideline to its generated answer.\n",
    "    \"\"\"\n",
    "    # Define the system prompt with the required instructions.\n",
    "    system_prompt = (\n",
    "        \"Your task is to assist a Quantitative Model Validator working in the Model Risk Management team of a bank, \"\n",
    "        \"to find answers to policy questions about Model Development Document (MDD) based on the provided context.\\n\"\n",
    "        \"Contents of the subsection(s) of MDD is used as the only input context to answer the Model Validation policy questions. \"\n",
    "        \"You are a highly accurate assistant who strictly answers only based on the information in the provided context.\\n\\n\"\n",
    "        \"Strictly follow these Generation Instructions:\\n\"\n",
    "        \"- Your response should be accurate, coherent, detailed, and descriptive by including all the important statistics, tables, terminologies, and definitions.\\n\"\n",
    "        \"- Your response should be relevant to the question being asked.\\n\"\n",
    "        \"- Your response should be honest, focused, and grounded in the provided context.\\n\"\n",
    "        \"- Do not change or assume any definition, terminology, statistical data, numerical information, or table information.\\n\"\n",
    "        \"- Always respond with \\\"Not found\\\" when you cannot find relevant information in the context.\\n\"\n",
    "        \"- Always respond with \\\"Not found\\\" if any information asked is not explicitly mentioned.\\n\"\n",
    "        \"- Use the important keywords and phrases from the context to frame your response.\\n\"\n",
    "        \"- Use bullet points only when required.\\n\"\n",
    "        \"- Only use the information provided under the specific product, business segment or aspect when answering questions. \"\n",
    "        \"If the context includes details about multiple products, ensure your response is limited to the product specified in the query. \"\n",
    "        \"Do not include information from other products, businesses, or other aspects.\\n\"\n",
    "    )\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Loop through each guideline.\n",
    "    for guideline in guidelines:\n",
    "        # Retrieve relevant document chunks from the vector store (top 3 results).\n",
    "        search_results = vector_store.search(guideline, k=3)\n",
    "        # Aggregate the content from the results.\n",
    "        context_chunks = [doc.content for (doc, score) in search_results if doc and score > 0]\n",
    "        context = \"\\n\\n\".join(context_chunks).strip()\n",
    "        # Truncate the context to avoid exceeding token limits.\n",
    "        context = truncate_text(context, max_tokens=max_context_tokens)\n",
    "        \n",
    "        # If there's no relevant context, return \"Not found\".\n",
    "        if not context:\n",
    "            answer = \"Not found\"\n",
    "        else:\n",
    "            # Append \"Answer:\" at the end of the prompt to guide the model.\n",
    "            prompt = system_prompt + \"\\n\\nContext:\\n\" + context + \"\\n\\nPolicy Question: \" + guideline + \"\\nAnswer:\"\n",
    "            answer = get_completion_fixed(prompt)\n",
    "        \n",
    "        results[guideline] = answer\n",
    "        print(f\"Guideline: {guideline}\\nAnswer: {answer}\\n{'-'*60}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Example guidelines list.\n",
    "guidelines = [\n",
    "    \"Briefly describe the business portfolio to which the model applies\",\n",
    "    \"Include the products and business segments offered by the business line\",\n",
    "    \"Describe the products of the LOB and portfolio to which this model applies.\",\n",
    "    \"Describe any current or planned changes in the products, channels, policies, programs, organization, or marketing practices that may impact the model under consideration.\",\n",
    "    \"Assess how close the current customer base to the target customer profile is.\",\n",
    "    \"Consider whether the customer base is likely to shift over the lifetime of the model.\",\n",
    "    \"Specify the current and possible future market conditions and the impact they may have on the portfolio and the model.\",\n",
    "    \"Describe the growth of the portfolio over the past 5, 10, X years, both in size and in significance to the balance sheet.\",\n",
    "    \"If this is a revalidation or the model replaces an existing model, highlight the key relevant changes on the business between the previous model developments and model validations, and this validation.\",\n",
    "    \"Include all the changes related to modeling, such as model framework and theory, variables, data sources, and programs; business changes, such as policy or strategy; environmental changes, such as competitor actions, economic changes, and political or regulatory changes; and any other changes that impact the model, its implementation, evaluation, and usage.\",\n",
    "    \"Include a table or summary of the portfolio, product, or business metrics of the business in the most recent and past periods. These can include metrics such as balances, losses, recoveries, number of accounts, average account size, credit limits, etc.\"\n",
    "]\n",
    "\n",
    "# To run the updated function (assuming vector_store is already instantiated and indexed):\n",
    "# results = run_model_validation_policy_questions_fixed(guidelines, vector_store)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
