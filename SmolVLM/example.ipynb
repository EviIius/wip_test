{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822f97bcccfe48e281b699f9ec54a61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAssistant: The first image shows a green statue of the Statue of Liberty standing on a stone pedestal in front of a body of water. \\nThe statue is holding a torch in its right hand and a tablet in its left hand. The water is calm and there are no boats or other objects visible. \\nThe sky is clear and there are no clouds. The second image shows a bee on a pink flower. \\nThe bee is black and yellow and is collecting pollen from the flower. The flower is surrounded by green leaves.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from transformers.image_utils import load_image\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\"\"\"\n",
    "Assistant: The first image shows a green statue of the Statue of Liberty standing on a stone pedestal in front of a body of water. \n",
    "The statue is holding a torch in its right hand and a tablet in its left hand. The water is calm and there are no boats or other objects visible. \n",
    "The sky is clear and there are no clouds. The second image shows a bee on a pink flower. \n",
    "The bee is black and yellow and is collecting pollen from the flower. The flower is surrounded by green leaves.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "# image1 = load_image(\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\")\n",
    "# image2 = load_image(\"https://blog.imglarger.com/content/images/2023/06/How-to-Get-a-JPG-File-with-High-Resolution-Tools-and-Tips.jpg\")\n",
    "\n",
    "image1 = Image.open(\"C:/Users/rbrul/Documents/GitHub/wip_test/SmolVLM/snowmount.jpg\")\n",
    "image2 = Image.open(\"C:/Users/rbrul/Documents/GitHub/wip_test/SmolVLM/waterhand.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n"
     ]
    }
   ],
   "source": [
    "# Initialize processor and model\n",
    "# processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "# model = AutoModelForVision2Seq.from_pretrained(\n",
    "#     \"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     _attn_implementation=\"flash_attention_2\" if DEVICE == \"cuda\" else \"eager\",\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# Initialize processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-256M-Instruct\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-256M-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "User:\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Can you describe the two images in 2 sentences with some detail?\n",
       "Assistant: In the first image, a person is standing in the snow, while in the second image, a person's hand is touching the water."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create input messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe the two images in 2 sentences with some detail?\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image1, image2], return_tensors=\"pt\")\n",
    "inputs = inputs.to(DEVICE)\n",
    "\n",
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "answer = generated_texts[0]\n",
    "display_markdown(answer, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
